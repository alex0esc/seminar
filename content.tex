\section{Einleitung}
	\subsection{Forschungsfrage und Zielsetzung}
	Seit dem 30. November 2023 ist der Chatbot ChatGPT veröffentlicht und frei nutzbar. 
	Nur nach weniger als zwei Monaten hatte ChatGPT bereits 100 Millionen Nutzer \cite[S. 15]{spitzer23}.
	Wegen des großen Erfolges begannen schon nach kurzer Zeit weitere Unternehmen wie Google ihre eigenen 
	Chatbots zu entwickeln. Mitlerweile gibt es immer umfangreichere sowie leistungsfähigere KI und
	deren Entwicklung schreitet unglaublich schnell voran.
	
	Diese Technologie hat einen immer größer werdenden Einfluss auf unsere moderne Gesellschaft. 
	Chatbots sind für viele Menschen bereits Teil ihres Alltags und helfen in der Schule oder
	im Studium, aber auch im Beruf, beispielsweise dann, wenn es darum geht längere Texte zu verfassen \cite[S. 175, S. 185]{shaji23}.
	Auf der andere Seite gibt es sogar Chatbots die keinen praktischen Nutzen haben und dazu gedacht
	sind, dass man sich mit ihnen die Zeit vertreibt, indem man z. B. emotionale gespräche mit ihnen 
	führt. Diese Art der Chatbots sollen als eine art KI Fruend dienen, sie sind vor allem in form
	von Anwendungen aus dem Play Store \& App Store bekannt.
	
	Dabei ist es wichtig so eine Technologie richtig einordnen zu können. Jedoch wissen die wenigsten
	wie Chatbots funktionieren, was dazu führt kann, dass deren fähigkeiten oft flasch eingeschätzt werden. 
	Darum soll in dieser Arbeit der Frage nach gegangen werden, wie das Bild von KI Chatbots in der 
	Gesellschaft aussieht, bzw. was an diesem Bild problematisch ist. 

	Mit meiner Arbeit verfolge ich das Ziel aufzuzeigen, welcher Eindruck in den Medien von Chatbots  
	vermittelt wird. Daraus sollen Schlüsse gezogen werden, was die meisten Menschen über diese Form 
	der KI denken. Außerdem will ich in meiner Arbeit gut verständlich erkären, warum dieses Bild der 
	Chatbots bzw. KI oft fehlerhaft ist. Dazu wird näher auf die Funktionsweise dieser Programme 
	eingegangen. Nach dem Lesen der Arbeit soll man ein grundlegendes Verständnis von Chatbots haben 
	und mit Informationen diesbezüglich aufgeschlossener umgehen können. 

	\clearpage
	\subsection{Methodik und Aufbau} 
	Im ersten Teil meiner Arbeit werde ich auf einige Beispiele eingehen, die zeigen, dass leicht
	ein falscher Eindruck von KI, also Chatbots, vermittelt wird.
	Als erstes werden über KI Chat Apps behandelt. Dabei gehe ich auf Versprechen ein, 
	die von den Entwicklern der Apps gemacht werden. Außerdem will ich durch Bewertungen zeigen,
	wie die Chatbots in solchen Programme auf die Nutzer wirken.
	Danach will ich anhand einiger populärwissenschaftlichen Artikel zeigen, dass beispielsweise
	die Funktionsweise von KI des Öfteren flasch beschrieben wird oder dass es bei solchen Quellen
	leicht zu Missverständnissen kommen kann.
	Zuletzt gehen ich noch konkreter auf das Thema Chatbots und IQ-Tests ein. Hier erläutere ich
	erst ein mal, welche Bedeutung IQ-Tests im Bezug zu Chatbots haben und wozu deren Ergebnisse
	gerne verwendet werden.
	
	Der zweite Teil der Arbeit behandelt zunächst die Funktionsweise von Chatbots.
	Erst ein mal müssen ein paar wichtige Begriffe geklärt werden und danach wird 
	auf das LLM und den GPT eingegangen. Die grundlegende Funktionsweise von KI Chatbots
	wird hierbei leichtverständlich vermittelt.
	Mit diesem neun Wissen wird dann auf das Thema AGI behandelt. Es soll dann anhand
	einiger Beispiele gezeigt werden, warum wir zum aktuellen Zeitpunkt noch keine AGI
	entwickelt haben. Das Thema AGI passt hier sehr gut, denn wie im ersten Teil der 
	Arbeit gezeigt wird, passiert es schnell, dass akutelle KI flasch dargestellt wird, 
	nähmlich gerne als AGI.     	    
	Mit dem neun Wissen sollen dann die Missverständnisse und Problematiken aus dem ersten 
	Teil der Arbeit aufgeklärt werden. Zunächst soll verdeutlicht werden, dass KI noch nicht
	intellegent ist und auch keine menschlichen Gefühle oder Emotionen hat. Danach sollen 
	Missverständnisse aus den voher aufgezeigten Artikeln aufgekärt werden. Zuletzt wird die
	Problematik mit IQ-Tests, die von Chatbots bearbeitet wurden, diskutiert.  	
	
	
	\clearpage
\section{Chatbots in der Gesellschaft}

	\subsection{Chatbots mit Gefühlen}
	Eine kurze Erklärung vorab: Die meisten kennen vermutlich bekannete Chatbots wie ChatGPT, die dazu
	entwickelt wurden uns bei diversen Aufgaben zu unterstützen. Im Gegensatz dazu steht Character.AI, 
	eines der Unternehmen, die \glqq{}persönliche\grqq{} AEI\footnote{Artificial Emotional Intelligence} 
	anbieteten \cite{cAI24}. Das bedeutet, dass die KI dazu entworfen wurde, soziale Gespräche zu führen.
	Man kann zwischen verschiedenen Chatbots, die meist fiktive Charaktäre räpresentierten, wählen. Sie
	sind darauf ausgelegt möglichst emotional und menschlich zu reagieren und oft stehen dabei sehr 
	persönliche Themen im Vordergrund z. B. Einsamkeit, Freundschaft, Empathie oder sogar Liebesbeziehungen. 
	
	Das dabei eine emotionale Verbindung zu Chatbots entstehen kann ist kein Wunder und dafür reicht ein 
	Chatbot aus, der nur begrenzte soziale Fähigkeiten hat \cite{chen24}. KI ist für viele Menschen also 
	nicht nur eine parktische Anwendung, die im Alltag hilfreich ist, sonder hat für einige Personen auch
	emotionalen Mehrwert. Ob und wieso das Kritisch gesehen werden muss wird \ref{s2ss4sss1} diskutiert.  

	Character.AI ist nur einer von mehreren Unternehmen, die persönliche AEI anbieten, und das mit Erfolg. 
	Seit September 2022 ist Character.AI frei verfügbar und hat zum jetzigen Zeitpunkt August 2024 bereits
	über 10 Millionen Downloads bei Google Play. Auf Grund der schnellen Weiterentwicklung von KI und des 
	global stärker werdenden Gefühls von Einsamkeit ist demnach zu erwarten, dass die soziale Bedeutung 
	von Chatbots zunehmen wird \cite{chen24}. 
	
	
	\clearpage		
	\subsection{Mediale Berichterstattung}
	Die Medien spielen bei der Berichterstattung über KI eine entscheidende Rolle. Sie tragen nicht nur dazu
	bei, die Öffentlichkeit über aktuelle Entwicklungen und Innovationen zu informieren, sondern sind auch 
	verantwortlich dafür, komplexe technische Zusammenhänge verständlich zu vermitteln. Doch genau heir kann
	es auch zu Problemen kommen, wodurch eine falsche Auffassung von KI Chatbots entsteht.

	Ein beispiel hierfür ist das Demonstrationsvideo von Google zu ihrem Chatbot Gemini \cite{gminiDemo2023}. 
	Das Video zeigt eine Person, die mit dem Chatbot Gemini live interagiert und ihm Fragen stellt. Dabei
	zeichnet die Person beispielsweise ein Bild von einer Ente und stellt dem Chatbot immer wieder Fragen dazu.
	Später im Video deutet die Person durch handbewegungen an, dass sie mit dem Chatbot das Spiel \glqq{}Schere
	Stein Papier\grqq{} spielen will. Der Chatbot antwortet, dass er die Herausforderung annimmt. Das Video
	betont damit vor allem die Interaktivität zwischen Gemini und der anwesenden Person. Außerdem zeigt das
	video einen autonomen Chatbot, der aus einem bestimmten Context Schlüsse zieht, welche Antwort gefragt ist. 

	In vielen Artikeln zu Chatbots wird deren Funktionsweise und Training erklärt. Maria Gramsch erklärt in 
	ihrem Artikel wie ChatGPT funktioniert \cite{gramsch23}. Sie fasst sich hierbei kurz und erklärt unteranderem
	auch das Training von Chatbots. In dem Artikel ist zwei mal zu lesen, dass das Trainig von ChatGPT stets
	unvollendet ist und dass der Chatbot aus Konversationen mit den Nutzern immer weiter dazu lernt. Dadurch wird
	der Eindruck vermittelt, dass ChatGPT wie ein Mensch aus seinen Erfahrungen lernt.

	Was genau an den gennanten Beispielen für die Berichterstattung falsch ist wird in \ref{s2ss4sss2}
	verdeutlicht. Beide gennanten Fälle sorgen dafür, dass KI besser dargestellt wird, als sie eigentlich
	ist. Dafür gibt es vierschiedene Hintergründe, wie z. B. Marketing im fall von Gemini oder mangelndes
	Wissen bezogen auf Chatbots. Problematisch ist, dass vor allem für die Personen, die nur wenig Verständnis 
	von KI besitzen durch solche Informationsquellen leicht einen flaschen Eindruck davon bekommen können, zu
	was Chatbots fähig sind.	 	 
	
	
	\subsection{Chatbots und IQ-Tests}
	Mit der steigenden Zahl an KI Modellen, wird KI-Benchmarking\footnote{Verglich von KI-Systemen} immer wichtiger. 
	Außerdem stellt sich die Frag, wie Intellegent ein Chatbot verglichen mit einem Menschen ist. IQ-Tests 
	bieten eine Möglichkeit das zu tun, sie sind dazu entworfen Intellegenz so gut wie möglich zu messen und das 
	funktioniert auch bei KI. Jedoch ist es wichtig die Ergebnisse, welche KI in IQ-Tests erzielt, kritisch zu
	sehen und richtig zu deuten.

	Eka Roivainen schreibt in ihrem Artikel, wie er mit dem damals neu veröffentlichten ChatGPT-4 einen IQ-Test
	durchgeführt hat \cite{roivainen23}. Sie schreibt zu beginn des Artikels, dass sie sich dafür interessiere, wie
	schlau ChatGPT im Vergleich zu menschlichen Standarts ist. Im verbalen Teil des verwendeten WAIS-III Tests
	erklärt sie, der Chatbot hat einen Wert von 155 erzielt und ist damit besser als 99,9\% der menschliche Teilnehmer.
	Der Artikel wurde mehreren anderen Artikeln zitiert, wie beispielweise von Sandra Blütermann in ihrem Artikel
	\cite{blutermann23}. In einem Interview von Sky News Australia erklärt Mo Gawdat ein ehmaliger Chief Business
	Officer von Google ebenfalls, dass ChatGPT einen IQ von 155 habe und damit fast so intellegent wie Alber Einstein
	sei \cite{gawdat23}.

	Betrachtet man das Ergebnis, was Roivainen mit ChatGPT-4 in ihrem IQ-Test erziehlt hat könnte man meinen,
	dass KI dem Menschen bereits überlegen ist. Mo Gawdat sagt das sogar schon fast wörtlich in seinem Interview:
	\glqq{}Der IQ von ChatGPT-4 wird auf 155 geschätzt, das ist viel schlauer als der durchschnittliche Mensch\grqq{} 
	\cite{gawdat23}. In \ref{s2ss4sss3} werden die Ergebnisse, von ChatGPT-4 im WAIS-III Test genaur betrachtet.
	Darüber hinaus wird die Aussage von Mo Gawdat über die Intellegenz von ChatGPT-4, diskutiert und widerlegt. 	

\clearpage	
\section{Funktionsweise von Chatbots}
	\subsection{Begriffe und Grundlagen}\label{s2ss1}
	Um das nächste Kapitel verstehen zu können, müssen zunächst einige wichtige Begriffe und Sachverhalte erklärt 
	werden. Natürlich kann im Rahmen dieser Arbeit nicht eine komplette Erklärung rund um LLM und GPT bis ins Detail
	gewährleistet werden, darum beziehe ich mir hier auf das Nötigste, um die folgenden Teile der Arbeit gut verstehen
	zu können: 
	
	\begin{itemize}
		\item \textbf{Neuronale Netze}: Man kann ein Neuronales Netz als eine Mathematische Funktion sehen,
		die eine Anzahl $n$ an Werten annimt und eine Anzahlt $m$ an Werten ausgibt. Diese Werte kann man auch als Eingabe-
		und Ausgabevektor sehen: 		
		
		\begin{equation}\label{nueral_network_function}	
			f(\vec{v}) = \vec{w}\textnormal{,\qquad wobei } \vec{v} \in \mathbb{R}^n \textnormal{ und } \vec{w} \in \mathbb{R}^m
		\end{equation}  
		\vspace{0.0cm}
		
		Die Funktion $f$ hat zahlreiche Parameter (oft mehrere Milliarden), die man genau so anpassen will, dass aus unterschiedlichen 
		Eingabevektoren die gewünschten Ausgabevektoren werden und genau hier kommt das Training ins Spiel. Durch
		Training ist es möglich die Zahlreichen Parameter des Netzwerks so einzustellen, dass sich die Werte der 
		Ausgabevektoren möglichst gut an die gewünschten Werte annähern \cite[S. 4f]{aggarwal2018}.  
		
		\item \textbf{NLP}: Natural Language Processing ist ein Feld der KI, dass darauf spezialisiert ist natürliche 
		Sprache zu analysieren, transformieren oder zu generieren.  
		
		\item \textbf{LLM}: Ein Large Language Model ist, wie der Name schon sagt ein großes KI Model unserer Sprache.
		LLMs sind auf NLP spezialisiert und funktionieren unter der Verwendung von Neuronalen Netzen.

		\item \textbf{Transformer}: Die Transformerachitektur ist ein neuronales Netzwerk-Modell, das erstmals im 
		bekannten Forschungsartikel \glqq{}Attention is all You Need\grqq{} von Forschern bei Google vorgestellt wurde 
		\cite{vaswani2017}. Transformer in Verbindung mit Chatbots werden in \ref{s2ss1} genauer erklärt.
		
		\item \textbf{GPT}: Ein Generative Pre-Trained Transformer ist ein LLM das sich die Transformerachitektur 
		zu Nutze macht um ein deutlich besseres Ergebnis bei der Sprachverarbeitung zu erzielen. Diese GPTs sind
		der Grund für den Fortschritt im Bereich NLP und sie werden derzeit in fast allen bekannten Chatbot Modellen, 
		wie ChatGPT und Gemini verwendet \cite[S. 2]{gemini2024}, \cite[S. 1]{openAI2024}.  
		
		\item \textbf{Token}: Wenn ein Chatbot eine Nachricht verarbeitet, dann wird diese zunächst in mehrere kleinere 
		Tokens zerlegt. Tokens helfen bei der Sprachverarbeitung, indem sie Textblöcke in einzelne Zeichenfolgen zerlegen.  
		Zur vereinfachung kann man sich auch vorstellen, dass ein Token ein Wort räpresentiert.   
		%referenz später hinzufügen!!!
	\end{itemize}	
	\clearpage
	
	
	\subsection{Transformer und Chatbots}\label{s2ss2}
	Im Folgenden wrid der schematische Aufbau eines Transformers erklärt. Wie schon in \ref{s2ss1} erwähnt wurde 
	ist ein Transformer ein neuronales Netzwerk-Modell. Das heißt wie in \ref{nueral_network_function} beschrieben 
	nimmt dieser Transformer einen Vektor an rationalen Zahlen als Eingabe und gibt ebenso einen Vektor aus.      
	
	
	\tikzstyle{concept} = [rectangle, rounded corners, minimum width=2cm, minimum height=0.8cm, text centered, draw=black, fill=orange!40, line width = 0.5mm]
	\tikzstyle{arrow} = [thick,->,>=stealth, line width = 0.5mm]
	\begin{tikzpicture}[node distance=1.5cm]
		% Nodes
		\node (input) [concept, fill=green!40] {Eingabe};
		\node (embedding) [concept, above of=input] {Embedding};
		\node (encoding) [concept, right of=embedding, fill=yellow!40] (encoding) at (3, 1.5) {Postitional Encoding};
		\node (attention) [concept, above of=embedding] {Masked Multi-Head Attention};
		\node (normal) [concept, above of=attention, fill=blue!40] at (0, 2.325) {Normalisierung};
		\node (forward) [concept, above of=normal] {Feed Forward};
		\node (normal1) [concept, above of=forward, fill=blue!40] at (0, 4.65) {Normalisierung};
		\node (linear) [concept, above of=normal1] {Linear}; 
		\node (softmax) [concept, above of=linear, fill=purple!40] {Softmax};
		\node (output) [concept, above of=softmax, fill=green!40] {Ausgabe};
		% Arrows
		\draw [arrow] (input) -- (embedding);	
		\draw [arrow] (encoding) -- (embedding);
		\draw [arrow] (embedding) -- (attention);
		\draw [arrow] (normal) -- (forward);
		\draw [arrow] (normal1) -- (linear);
		\draw [arrow] (linear) -- (softmax);
		\draw [arrow] (softmax) -- (output);
		\draw [arrow, bend right=100] (output) to (input);
		\draw[rounded corners, line width=0.5mm] (-3.2, 2.3) rectangle (3.2, 6.8);  
		\node[right] at (3.3, 5) {\small{N = 96, bei GPT-3.5}};
		%\draw [highlight] (input) -- ++(-1,1) -- ++(4,0) -- ++(0,-2) -- cycle;
	\end{tikzpicture}
	
	
	Die erste Aufgabe eines Chatbots ist es also Text zunächst in einzelne Tokens aufzuteilen und dann disen Tokens 
	einen individuellen Vektor zu zu ordnen. Das wird auch als Embedding bezeichnet. Durch das unwandeln von Tokens in 
	einen Vektor kann das Netzwerk Text mathematisch verarbeiten. Weil die einzelnen Tokens nicht der Reihe nach sondern 
	unabhängig von einander und parallel zu einander verarbeitet werden, muss deren Position im Satz mit in den Eingabevektor 
	encodiert werden \cite[S. 2f]{vaswani2017}. Das liegt daran das bei vielen Wörtern die Position im Satz eine 
	Entscheidende Rolle dafür spielt, was der Satz aussagt:

	\vspace{3mm}
	\emph{Der Mann jagt den Hund.} 	
	\space $\neq$ \space
	\emph{Der Hund jagt den Mann.}
	
	\clearpage
	\noindent
	Die grundlegende Funktionsweise besteht darin, dass der Transformer diese Tokens in Vektoren umwandelt, verarbeitet und dann 
	als Ausgabe errechnet, welches Token mit welcher Wahrscheinlichkeit als nächstes folgt. Natürlich wäre ein Chatbot der nur
	ein Token als Antwort geben könnte ziemlich nutzlos. Das Problem ist aber einfach zu lösen, indem man dem Transformer
	die Tokens der vorherigen Eingabe und dazu die neu generierten Tokens gibt. Das wird auch als Selbstregression bezeichnet und 
	bedeutet, dass der Transformer seine Ausgabe wieder als Eingabe verwendet \cite[S. 2]{vaswani2017}.  

	Nach dem Embedding folgt die eine Masked Multi-Head Attention Schicht\footnote{Teil eines neuronalen Netzwerks}.
	Im fall eines generativen Transformers wird sich hier der  Self-Attention Mechanismus zunutze gemacht \cite[S. 2f]{turner2024}. 
	Dabei wird zunächst errechnet wie stark der Zusammenhang zwischen zwei Tokens ist \cite[S. 4]{vaswani2017}. Hat man zu 
	Beispiel die Frage, \emph{Wie nennt man ein großes Haus?} als Eingabe, könnten die errechneten Zusammenhänge für das 
	Wort Haus so aussehen: 
	
	\vspace{5mm}
	\begin{tabular}{ |c|c| }
  		\hline
	  	\multicolumn{2}{|c|}{Zusammenhang mit Haus: } \\
	  	\hline
	  	\emph{Wie} & 0,046 \\
	  	\hline
	  	\emph{nennt} & 0,08 \\
		\hline
	  	\emph{man} & 0,023 \\
	  	\hline
		\emph{ein} & 0,12 \\
	  	\hline
		\emph{großes} & 0,7 \\
	  	\hline
		\emph{haus} & 0,031 \\
		\hline
		\emph{?} & 0,001 \\
		\hline
	\end{tabular}
	\vspace{5mm}
	
	\noindent Weil sich das Adjektiv \emph{großes} auf das Nomen \emph{Haus} bezieht erkennt ein trainierter Transformer hier
	einen starken Zusammanhang. Durch diese errechneten Zusammenhänge zwischen den Tokens kann das Netzwerk abwägen, welches
	Token auf welches andere Token wie viel einfluss nehmen soll.	
		
	Nach der Multi-Head Attention folgt eine Normalisierung, welche dabei hilft die Vektoren zu verarbeiten. 
	Normalisirungen sind zwar Teil der Transformerachitektur aber nicht entscheidend für ein schematisches Verständnis
	und werden hier nicht genauer beschrieben\cite[S.3]{vaswani2017}. 
	\clearpage
	\noindent
	Der zweite bedeutende Teil eines Transformers folgt direkt auf den attention Block und nennt sich Feed Forward Block.
	Im Feed Forward Block befinden sich c.a. zwei drittel der Parameter \cite{geva2024}. Parameter bestimmer bekanntlicher weise
	die Ausgabewerte einer Funktion oder eines neuronalen Netzwerks. Im Fall eines Chatbots bestimmen diese Paramter, wie auf 
	einen Satz den der Transformer als eingabe bekommt geantwortet wird. Bei diesen Antworten reicht es meistens aber nicht aus, 
	einfach nur Zusammenhänge zwischen Wörtern zu erkennen, wie oben erklärt, sondern man bennötigt Hintergrundwissen zum Thema 
	für eine konstruktive Antwort.

	Im obigen Satz muss man zum Beispiel nicht nur verstehen, das es um ein \emph{großes Haus} geht sondern auch wissen welche alternativen
	Wörter es dafür gibt um die Frage zu beantworten. Dafür braucht man den Feed Forward Block, er kann als Gedächnis des Transformers gesehen
	werden. Da sich hier ein großteil der Parameter befindet ist hier auch ein großteil des Wissens bzw. der Datan, die ein neuronales
	Netzwerk gelernt hat gespeichert \cite{geva2024}.
	\vspace{5mm}
	Im Attention Block werden also zusammenhänge zwischen den Tokens erkannt und dann Informationen zwischen den Tokens übertragen
	und im Feed Forward Block wird dann noch auf die eingehenden Tokens mit bestimmten issen, welches das Netzwerk besitzt reagiert.
	
	Wichtig ist, dass dieser Ablauf von Attention und Feed Forward in einem Transformer mehrmals wiederholt wird, damit auch längere komplexe Texte mit
	komplizierten Zusammenhängen sinnvol verarbeitet werden können.
	
	Am Ende des Transformer befinden sich noch eine Lineare und eine Softmax Schicht \cite{aggarwal2018}. Sie sind dazu dar die Ausgabe des Transformers
	in einen Vektor zu überführen, der allen bekannten Tokens eine Wahrscheinlichkeit zuweist. Darunter wählt man dann meist das Token 
	mit der höchsten Wahscheinlichkeit aus und fügt es dem Text hinzu. Diesen Prozess wiederholt man dann so lange, bis der Transformer
	ein EOS-Token\footnote{End-of-Sequence-Token} generiert und damit den Abschluss seiner Antwort signalisiert.
	
	
	%chat gpt 3.5 tech report oder specs finden
	%aggarwal2018?
	\subsection{Warum ist das noch nicht AGI?}\label{s2ss3}
	\subsection{Was folgt daraus?}\label{s2ss4}
		\subsubsection{Immer noch nur Algorithmen}\label{s2ss4sss1}
		%1. KI ist nicht wirklich intellegent, wurde darauf trainiert so zu tun als hätte sie emotionen!!! JA!
		%1. KI hat eigentlich keine emotionen JA!
		%Other. negative einflüssen, wenn man zu sozial abhängig von KI wird
		\subsubsection{Das falsche Bild in den Medien}\label{s2ss4sss2}
		%2. was ist daran falsch, konkret kein Training während man mit der KI schreibt JA!
		%2. warum ist es falsch, KI ist nicht wirklich so interaktive wie dargestellt, Gemini hatte diese features noch nicht, extra promts JA!
		%Other. warum ist das problematisch
		\subsubsection{IQ-Tests mit wenig Aussagekraft}\label{s2ss4sss3}
		%3. verbaler IQ-Test fragwürdig = Mensch gegen Taschenrechner, es wird auf Trainingsdaten zurück gegriffen Naja
		%3. vergleich mit IQ-Test von Mensch schwirig JA!
\section{Fazit: KI kann leicht missverstanden werden}\label{s3}